name: Website Optimization

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: write

jobs:
  optimize-website:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Check Repository Structure
      run: |
        echo "Repository structure:"
        ls -la
        echo ""
        echo "Looking for website files..."
        find . -name "*.html" -type f | head -10
        echo ""
        echo "Looking for directories..."
        find . -type d -name "*version*" -o -name "*website*" -o -name "*final*" | head -10

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install Dependencies
      run: |
        pip install beautifulsoup4 pillow lxml

    - name: Find Website Directory and Optimize
      run: |
        # Find the correct website directory
        WEBSITE_DIR="."
        
        if [ -d "final-version" ]; then
          WEBSITE_DIR="final-version"
          echo "Found website files in: final-version/"
        elif [ -d "WEBSITE/final-version" ]; then
          WEBSITE_DIR="WEBSITE/final-version"
          echo "Found website files in: WEBSITE/final-version/"
        elif [ -d "website" ]; then
          WEBSITE_DIR="website"
          echo "Found website files in: website/"
        else
          echo "Using root directory"
        fi
        
        echo "Working in directory: $WEBSITE_DIR"
        cd "$WEBSITE_DIR"
        
        # Create optimization script
        cat > optimize_images.py << 'EOF'
        #!/usr/bin/env python3
        import os
        import re
        from bs4 import BeautifulSoup
        try:
            from PIL import Image
        except ImportError:
            Image = None

        def get_image_dimensions(image_path):
            if not Image:
                return None, None
            try:
                with Image.open(image_path) as img:
                    return img.size
            except:
                return None, None

        def optimize_html_images(html_file):
            print(f"Processing: {html_file}")
            with open(html_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            soup = BeautifulSoup(content, 'html.parser')
            images = soup.find_all('img')
            changes_made = False
            
            for img in images:
                src = img.get('src', '')
                if not src or src.startswith('http' ):
                    continue
                
                # Get image dimensions
                image_path = src.lstrip('./')
                if os.path.exists(image_path):
                    width, height = get_image_dimensions(image_path)
                    if width and height:
                        if not img.get('width'):
                            img['width'] = str(width)
                            changes_made = True
                        if not img.get('height'):
                            img['height'] = str(height)
                            changes_made = True
                
                # Add loading="lazy"
                if not img.get('loading') and 'hero' not in src.lower() and 'logo' not in src.lower():
                    img['loading'] = 'lazy'
                    changes_made = True
                
                # Add object-fit style
                current_style = img.get('style', '')
                if 'object-fit' not in current_style:
                    if current_style:
                        new_style = current_style + '; object-fit: cover;'
                    else:
                        new_style = 'object-fit: cover;'
                    img['style'] = new_style
                    changes_made = True
                
                # Add alt if missing
                if not img.get('alt'):
                    if 'logo' in src.lower():
                        img['alt'] = 'Melissa Photography Paris Logo'
                    else:
                        img['alt'] = 'Professional Photography by Melissa Paris'
                    changes_made = True
            
            if changes_made:
                with open(html_file, 'w', encoding='utf-8') as f:
                    f.write(str(soup))
                print(f"âœ… Optimized: {html_file}")
                return True
            else:
                print(f"â­ï¸ No changes needed: {html_file}")
                return False

        # Process all HTML files
        html_files = []
        for root, dirs, files in os.walk('.'):
            if '.git' in root or 'node_modules' in root:
                continue
            for file in files:
                if file.endswith('.html'):
                    html_files.append(os.path.join(root, file))

        print(f"Found {len(html_files)} HTML files")
        optimized_count = 0
        for html_file in html_files:
            if optimize_html_images(html_file):
                optimized_count += 1

        print(f"ðŸŽ‰ Optimized {optimized_count} HTML files with images")
        EOF
        
        python optimize_images.py
        
        # CSS Minification
        cat > minify_css.py << 'EOF'
        #!/usr/bin/env python3
        import os
        import re
        from bs4 import BeautifulSoup

        def simple_css_minify(css_content):
            # Remove comments
            css_content = re.sub(r'/\*.*?\*/', '', css_content, flags=re.DOTALL)
            # Remove extra whitespace
            css_content = re.sub(r'\s+', ' ', css_content)
            # Remove spaces around certain characters
            css_content = re.sub(r'\s*([{}:;,>+~])\s*', r'\1', css_content)
            return css_content.strip()

        def minify_css_file(css_file):
            with open(css_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            minified = simple_css_minify(content)
            
            # Create minified version
            base_name = os.path.splitext(css_file)[0]
            min_file = f"{base_name}.min.css"
            
            with open(min_file, 'w', encoding='utf-8') as f:
                f.write(minified)
            
            return min_file

        # Find and minify CSS files
        css_files = []
        for root, dirs, files in os.walk('.'):
            if '.git' in root or 'node_modules' in root:
                continue
            for file in files:
                if file.endswith('.css') and not file.endswith('.min.css'):
                    css_files.append(os.path.join(root, file))

        print(f"Found {len(css_files)} CSS files to minify")
        minified_count = 0
        for css_file in css_files:
            try:
                min_file = minify_css_file(css_file)
                minified_count += 1
                print(f"âœ… Minified: {css_file}")
            except Exception as e:
                print(f"âŒ Error minifying {css_file}: {e}")

        print(f"ðŸŽ‰ Minified {minified_count} CSS files")
        EOF
        
        python minify_css.py
        
        # SEO Optimization
        cat > optimize_seo.py << 'EOF'
        #!/usr/bin/env python3
        import os
        from bs4 import BeautifulSoup

        def optimize_seo(html_file):
            with open(html_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            soup = BeautifulSoup(content, 'html.parser')
            changes_made = False
            
            # Add lang attribute to html tag
            html_tag = soup.find('html')
            if html_tag and not html_tag.get('lang'):
                if 'fr' in os.path.basename(html_file):
                    html_tag['lang'] = 'fr'
                else:
                    html_tag['lang'] = 'en'
                changes_made = True
            
            # Add meta viewport if missing
            if not soup.find('meta', attrs={'name': 'viewport'}):
                if soup.head:
                    meta_viewport = soup.new_tag('meta')
                    meta_viewport.attrs['name'] = 'viewport'
                    meta_viewport.attrs['content'] = 'width=device-width, initial-scale=1.0'
                    soup.head.append(meta_viewport)
                    changes_made = True
            
            # Add meta description if missing
            if not soup.find('meta', attrs={'name': 'description'}):
                if soup.head:
                    meta_desc = soup.new_tag('meta')
                    meta_desc.attrs['name'] = 'description'
                    meta_desc.attrs['content'] = 'Professional photographer in Paris - Melissa Photography. Specializing in proposals, couples, weddings and portraits.'
                    soup.head.append(meta_desc)
                    changes_made = True
            
            if changes_made:
                with open(html_file, 'w', encoding='utf-8') as f:
                    f.write(str(soup))
                print(f"âœ… SEO optimized: {html_file}")
                return True
            return False

        # Process all HTML files
        html_files = []
        for root, dirs, files in os.walk('.'):
            if '.git' in root:
                continue
            for file in files:
                if file.endswith('.html'):
                    html_files.append(os.path.join(root, file))

        optimized_count = 0
        for html_file in html_files:
            if optimize_seo(html_file):
                optimized_count += 1

        print(f"ðŸŽ‰ SEO optimized {optimized_count} HTML files")
        EOF
        
        python optimize_seo.py
        
        # Update sitemap and robots
        cat > update_config.py << 'EOF'
        #!/usr/bin/env python3
        import os
        from datetime import datetime

        # Generate sitemap.xml
        sitemap_content = '''<?xml version="1.0" encoding="UTF-8"?>
        <urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
        '''

        base_url = 'https://melissaphotography.paris'
        current_date = datetime.now( ).strftime('%Y-%m-%d')

        # Find all HTML files
        html_files = []
        for root, dirs, files in os.walk('.'):
            if '.git' in root or 'fonts' in root:
                continue
            for file in files:
                if file.endswith('.html') and not file.startswith('demo'):
                    rel_path = os.path.relpath(os.path.join(root, file), '.')
                    if rel_path.count('/') <= 1:
                        html_files.append(rel_path)

        for page in sorted(html_files):
            if page == 'index.html':
                url = f'{base_url}/'
            else:
                url = f'{base_url}/{page}'
            
            sitemap_content += f'''  <url>
            <loc>{url}</loc>
            <lastmod>{current_date}</lastmod>
            <changefreq>monthly</changefreq>
            <priority>0.8</priority>
          </url>
        '''

        sitemap_content += '</urlset>'

        with open('sitemap.xml', 'w', encoding='utf-8') as f:
            f.write(sitemap_content)

        # Update robots.txt
        robots_content = f'''User-agent: *
        Allow: /
        Sitemap: {base_url}/sitemap.xml
        '''

        with open('robots.txt', 'w') as f:
            f.write(robots_content)

        print(f"âœ… Updated sitemap.xml with {len(html_files)} pages")
        print("âœ… Updated robots.txt")
        EOF
        
        python update_config.py
        
        # Create security headers
        cat > _headers << 'EOF'
        /*
          X-Frame-Options: DENY
          X-Content-Type-Options: nosniff
          X-XSS-Protection: 1; mode=block
          Referrer-Policy: strict-origin-when-cross-origin
          Strict-Transport-Security: max-age=31536000; includeSubDomains

        /css/*
          Cache-Control: public, max-age=31536000

        /js/*
          Cache-Control: public, max-age=31536000

        /images/*
          Cache-Control: public, max-age=2592000
        EOF
        
        echo "âœ… Created security headers"
        
        # Go back to root for git operations
        cd ..

    - name: Commit Changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "Website Optimizer"
        
        if git diff --quiet && git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git add .
          git commit -m "ðŸš€ Auto-optimization: Images, CSS, SEO, Security improvements" || echo "Nothing to commit"
          git push || echo "Nothing to push"
        fi

    - name: Summary
      run: |
        echo "ðŸŽ‰ Website optimization completed successfully!"
        echo "âœ… Image lazy loading and dimensions added"
        echo "âœ… CSS files minified"
        echo "âœ… SEO meta tags enhanced"
        echo "âœ… Sitemap and robots.txt updated"
        echo "âœ… Security headers created"
